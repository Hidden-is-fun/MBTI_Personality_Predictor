{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_sample.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-for-tf2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC2hxnw7XN7K",
        "outputId": "7b3406fc-39f8-4c7a-cbfa-116fa4c54cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 184 kB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.63.0)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30535 sha256=1fd83378bec880d903070efa6580ae1bd20ed48510b51d16479af79d1ef185c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19472 sha256=2bf57add93f1491bdd79c967706838e1720a4c5cc674f60aef0712a2d7d64cce\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7911 sha256=e94411f1ea9a74908cf1874fd0197e646ccd34e430d524910b9714d44c2397f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQeCUlbpXgEJ",
        "outputId": "46d54563-c78a-4600-8b20-9ebdc2b80267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/app\") "
      ],
      "metadata": {
        "id": "LZtCzKEYXyOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHP_pEqaWMRH",
        "outputId": "b33299ed-c2f7-48e2-8b16-57d4ad4778a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "65/65 [==============================] - 17s 250ms/step - loss: 0.7068 - sparse_categorical_accuracy: 0.7437\n",
            "Epoch 2/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 0.4172 - sparse_categorical_accuracy: 0.8104\n",
            "Epoch 3/20\n",
            "65/65 [==============================] - 17s 256ms/step - loss: 0.2904 - sparse_categorical_accuracy: 0.8802\n",
            "Epoch 4/20\n",
            "65/65 [==============================] - 16s 252ms/step - loss: 0.1719 - sparse_categorical_accuracy: 0.9398\n",
            "Epoch 5/20\n",
            "65/65 [==============================] - 16s 250ms/step - loss: 0.0727 - sparse_categorical_accuracy: 0.9812\n",
            "Epoch 6/20\n",
            "65/65 [==============================] - 16s 250ms/step - loss: 0.0280 - sparse_categorical_accuracy: 0.9938\n",
            "Epoch 7/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 8/20\n",
            "65/65 [==============================] - 17s 255ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 9/20\n",
            "65/65 [==============================] - 17s 255ms/step - loss: 0.0024 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 0.0013 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 0.0010 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "65/65 [==============================] - 17s 255ms/step - loss: 8.1212e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 6.8271e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 5.1760e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 4.1506e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 3.2624e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 3.2886e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 2.7261e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 2.5191e-04 - sparse_categorical_accuracy: 1.0000\n",
            "3/3 [==============================] - 0s 118ms/step - loss: 0.5219 - sparse_categorical_accuracy: 0.8958\n",
            "I/E Trained Successfully!\n",
            " Accuracy: 89.58333134651184%\n",
            "INFO:tensorflow:Assets written to: ram://daad526a-dff3-4930-a673-f2a9f68423b0/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://daad526a-dff3-4930-a673-f2a9f68423b0/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model I/E saved.\n",
            "Epoch 1/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 0.5620 - sparse_categorical_accuracy: 0.8421\n",
            "Epoch 2/20\n",
            "65/65 [==============================] - 17s 257ms/step - loss: 0.3518 - sparse_categorical_accuracy: 0.8655\n",
            "Epoch 3/20\n",
            "65/65 [==============================] - 17s 255ms/step - loss: 0.2454 - sparse_categorical_accuracy: 0.9004\n",
            "Epoch 4/20\n",
            "65/65 [==============================] - 16s 252ms/step - loss: 0.1401 - sparse_categorical_accuracy: 0.9496\n",
            "Epoch 5/20\n",
            "65/65 [==============================] - 16s 252ms/step - loss: 0.0686 - sparse_categorical_accuracy: 0.9791\n",
            "Epoch 6/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 0.0311 - sparse_categorical_accuracy: 0.9910\n",
            "Epoch 7/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 0.0208 - sparse_categorical_accuracy: 0.9942\n",
            "Epoch 8/20\n",
            "65/65 [==============================] - 17s 256ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 9/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 9.8696e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 8.2436e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "65/65 [==============================] - 17s 255ms/step - loss: 6.0358e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 5.6729e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 4.0785e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 3.7130e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 3.2866e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 2.8912e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 2.3131e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 2.2953e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "65/65 [==============================] - 17s 256ms/step - loss: 1.8543e-04 - sparse_categorical_accuracy: 1.0000\n",
            "3/3 [==============================] - 0s 115ms/step - loss: 0.5531 - sparse_categorical_accuracy: 0.9167\n",
            "N/S Trained Successfully!\n",
            " Accuracy: 91.66666865348816%\n",
            "INFO:tensorflow:Assets written to: ram://b5e1ba11-bb99-4588-b66d-1dcda08dae3e/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://b5e1ba11-bb99-4588-b66d-1dcda08dae3e/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model N/S saved.\n",
            "Epoch 1/20\n",
            "65/65 [==============================] - 18s 256ms/step - loss: 0.8209 - sparse_categorical_accuracy: 0.5723\n",
            "Epoch 2/20\n",
            "65/65 [==============================] - 17s 257ms/step - loss: 0.4191 - sparse_categorical_accuracy: 0.8139\n",
            "Epoch 3/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 0.2599 - sparse_categorical_accuracy: 0.9015\n",
            "Epoch 4/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 0.1418 - sparse_categorical_accuracy: 0.9592\n",
            "Epoch 5/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 0.0674 - sparse_categorical_accuracy: 0.9838\n",
            "Epoch 6/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 0.0469 - sparse_categorical_accuracy: 0.9863\n",
            "Epoch 7/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 0.0406 - sparse_categorical_accuracy: 0.9866\n",
            "Epoch 8/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 0.0325 - sparse_categorical_accuracy: 0.9899\n",
            "Epoch 9/20\n",
            "65/65 [==============================] - 17s 255ms/step - loss: 0.0432 - sparse_categorical_accuracy: 0.9824\n",
            "Epoch 10/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 0.0131 - sparse_categorical_accuracy: 0.9952\n",
            "Epoch 11/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 12/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 7.1376e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 5.4335e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 5.1954e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 3.3562e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 3.5114e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "65/65 [==============================] - 17s 255ms/step - loss: 3.0655e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 2.4839e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 2.4667e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 2.0763e-04 - sparse_categorical_accuracy: 1.0000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 0.4199 - sparse_categorical_accuracy: 0.9036\n",
            "F/T Trained Successfully!\n",
            " Accuracy: 90.36458134651184%\n",
            "INFO:tensorflow:Assets written to: ram://e2279a2f-efe8-41fe-8e73-b6592bd6e7ea/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://e2279a2f-efe8-41fe-8e73-b6592bd6e7ea/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model F/T saved.\n",
            "Epoch 1/20\n",
            "65/65 [==============================] - 17s 255ms/step - loss: 0.8363 - sparse_categorical_accuracy: 0.5589\n",
            "Epoch 2/20\n",
            "65/65 [==============================] - 17s 255ms/step - loss: 0.5535 - sparse_categorical_accuracy: 0.7160\n",
            "Epoch 3/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 0.3856 - sparse_categorical_accuracy: 0.8314\n",
            "Epoch 4/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 0.2267 - sparse_categorical_accuracy: 0.9227\n",
            "Epoch 5/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 0.0910 - sparse_categorical_accuracy: 0.9779\n",
            "Epoch 6/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 0.0320 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 7/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 0.0119 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 8/20\n",
            "65/65 [==============================] - 17s 255ms/step - loss: 0.0046 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 0.0023 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 0.0012 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 9.5174e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 8.3122e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 6.3052e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 5.4702e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 4.6164e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 3.6249e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 3.4124e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "65/65 [==============================] - 17s 253ms/step - loss: 3.0754e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "65/65 [==============================] - 17s 254ms/step - loss: 2.4704e-04 - sparse_categorical_accuracy: 1.0000\n",
            "WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd40c22d560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd40c22d560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 101ms/step - loss: 0.7758 - sparse_categorical_accuracy: 0.8229\n",
            "J/P Trained Successfully!\n",
            " Accuracy: 82.29166865348816%\n",
            "INFO:tensorflow:Assets written to: ram://1710afe2-d780-4712-86d9-c001d6c0d4bf/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://1710afe2-d780-4712-86d9-c001d6c0d4bf/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model J/P saved.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from pandas import DataFrame\n",
        "from tensorflow.keras import layers\n",
        "import bert\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "# INFJ/ESTP\n",
        "\n",
        "class TEXT_MODEL(tf.keras.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "           vocabulary_size,\n",
        "           embedding_dimensions=128,\n",
        "           cnn_filters=50,\n",
        "           dnn_units=512,\n",
        "           model_output_classes=2,\n",
        "           dropout_rate=0.1,\n",
        "           training=False,\n",
        "           name=\"text_model\"):\n",
        "        super(TEXT_MODEL, self).__init__(name=name)\n",
        "\n",
        "        self.embedding = layers.Embedding(vocabulary_size,\n",
        "                          embedding_dimensions)\n",
        "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
        "                         kernel_size=2,\n",
        "                         padding=\"valid\",\n",
        "                         activation=\"relu\")\n",
        "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
        "                         kernel_size=3,\n",
        "                         padding=\"valid\",\n",
        "                         activation=\"relu\")\n",
        "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
        "                         kernel_size=4,\n",
        "                         padding=\"valid\",\n",
        "                         activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "\n",
        "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if model_output_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                             activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=model_output_classes,\n",
        "                             activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        l = self.embedding(inputs)\n",
        "        l_1 = self.cnn_layer1(l)\n",
        "        l_1 = self.pool(l_1)\n",
        "        l_2 = self.cnn_layer2(l)\n",
        "        l_2 = self.pool(l_2)\n",
        "        l_3 = self.cnn_layer3(l)\n",
        "        l_3 = self.pool(l_3)\n",
        "\n",
        "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1)  # (batch_size, 3 * cnn_filters)\n",
        "        concatenated = self.dense_1(concatenated)\n",
        "        concatenated = self.dropout(concatenated, training)\n",
        "        model_output = self.last_dense(concatenated)\n",
        "\n",
        "        return model_output\n",
        "\n",
        "\n",
        "def tokenize_text(text_input):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_input))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # hyper parameters\n",
        "    BATCH_SIZE = 128\n",
        "    EMB_DIM = 300\n",
        "    CNN_FILTERS = 100\n",
        "    DNN_UNITS = 256\n",
        "    OUTPUT_CLASSES = 10\n",
        "    DROPOUT_RATE = 0.5\n",
        "    NB_EPOCHS = 20\n",
        "    max_len = 2000\n",
        "\n",
        "    # raw data\n",
        "\n",
        "    data_set = pd.read_csv(\"mbti.csv\")\n",
        "    y_4axis = [[], [], [], []]\n",
        "    text = []\n",
        "    personality_type = ['IE', 'NS', 'FT', 'JP']\n",
        "    for _i in range(len(data_set)):\n",
        "        _text = data_set[\"posts\"][_i]\n",
        "        _text = _text[1:-1]\n",
        "        _text = re.sub(r'https?:\\/\\/.*?[\\s+]', ' ', _text)\n",
        "        _text = re.sub(r'http?:\\/\\/.*?[\\s+]', ' ', _text)\n",
        "        _text = _text.replace('...|||', ' ')\n",
        "        _text = _text.replace('|||', ' ')\n",
        "        text.append(_text)\n",
        "        for _ in range(4):\n",
        "          y_4axis[_].append(0 if data_set[\"type\"][_i][_] == personality_type[_][0] else 1)\n",
        "\n",
        "    # Creating a BERT Tokenizer\n",
        "    BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "\n",
        "    bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
        "    vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "    to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "    tokenizer = BertTokenizer(vocabulary_file, to_lower_case)\n",
        "\n",
        "    # Tokenize all the text\n",
        "    tokenized_text = [tokenize_text(i) for i in text]\n",
        "\n",
        "    for _i in range(4):\n",
        "      # Prerparing Data For Training\n",
        "      text_with_len = [[text, y_4axis[_i][i], len(text)]\n",
        "                for i, text in enumerate(tokenized_text)]\n",
        "      random.shuffle(text_with_len)\n",
        "      # text_with_len.sort(key=lambda x: x[2])\n",
        "      # sorted_text_labels = [(text_lab[0], text_lab[1]) for text_lab in text_with_len]\n",
        "      sorted_text_labels = [(text_lab[0][:max_len], text_lab[1]) for text_lab in text_with_len]\n",
        "      processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_text_labels, output_types=(tf.int32, tf.int32))\n",
        "      # batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
        "      batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((max_len,), ()))\n",
        "\n",
        "      TOTAL_BATCHES = math.ceil(len(sorted_text_labels) / BATCH_SIZE)\n",
        "      TEST_BATCHES = TOTAL_BATCHES // 20\n",
        "      batched_dataset.shuffle(TOTAL_BATCHES)\n",
        "      test_data = batched_dataset.take(TEST_BATCHES)\n",
        "      train_data = batched_dataset.skip(TEST_BATCHES)\n",
        "\n",
        "      VOCAB_LENGTH = len(tokenizer.vocab)\n",
        "      text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
        "                   embedding_dimensions=EMB_DIM,\n",
        "                   cnn_filters=CNN_FILTERS,\n",
        "                   dnn_units=DNN_UNITS,\n",
        "                   model_output_classes=OUTPUT_CLASSES,\n",
        "                   dropout_rate=DROPOUT_RATE)\n",
        "\n",
        "      if OUTPUT_CLASSES == 2:\n",
        "          text_model.compile(loss=\"binary_crossentropy\",\n",
        "                    optimizer=\"adam\",\n",
        "                    metrics=[\"accuracy\"])\n",
        "      else:\n",
        "          text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                    optimizer=\"adam\",\n",
        "                    metrics=[\"sparse_categorical_accuracy\"])\n",
        "\n",
        "      text_model.fit(train_data, epochs=NB_EPOCHS)\n",
        "      # text_model.fit(train_data, epochs=NB_EPOCHS,validation_data=test_data)\n",
        "      # test test data\n",
        "      results = text_model.evaluate(test_data)\n",
        "      print(f'{personality_type[_i][0]}/{personality_type[_i][1]} Trained Successfully!\\n Accuracy: {results[1] * 100}%')\n",
        "\n",
        "      joblib.dump(text_model, f'{personality_type[_i][0]}{personality_type[_i][1]}.pkl')\n",
        "      print(f'model {personality_type[_i][0]}/{personality_type[_i][1]} saved.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "EqUl86ZGXU-A"
      }
    }
  ]
}